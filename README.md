# <ins>Этап 5</ins> <br/>Оценка и анализ производительности сервера на базе кластера с репликацией данных
**Система и программные средства** 
| | |
|-|-|
| ОС | Ubuntu Linux 18.04 LTS x64-bit |
| ЦПУ | Intel(R) Celeron(R) N4000 CPU @ 1.10GHz |
| Объём RAM | 8 ГБ |
| Количество ядер ЦПУ | 2 |
| [wrk2](https://github.com/giltene/wrk2) | v. 4.0.0 |
| [async-profiler](https://github.com/jvm-profiling-tools/async-profiler) | 1.8.1 |

Аналитическое задание для отчётного этапа выполнено на основе реализации кластерного highload-сервера с поддержкой репликации данных. Результаты измерений быстродействия при выполнении запросов в **конфигурации с управлением репликами <em>(Replication control)</em>** сопоставлены с выводами нагрузочного тестирования, полученными в **базовом варианте распределённого обслуживания через шардирование <em>(Basic shard control</em>)** согласно задаче предыдущего этапа. Для оценки ключевых параметров производительности - задержки и интенсивности операций сервера, а также времени ожидания отклика на стороне клиента - выбран инструмент симуляции запросов <em>wrk2</em>; профилирование рабочей нагрузки процессора, памяти и программных средств управления параллельным доступом к данным проведено с использованием ПО <em>async-profiler</em>. Релевантные контексту статистика и профили (изображения в стиле flamegraph-визуализации) получены в ходе последовательных сеансов подачи PUT- и GET-запросов в течение фиксированного периода (7 минут) стабильного обмена данными с пулом клиентов (число соединений с клиентами, симулируемых в каждой конфигурации, установлено равным 64, количество параллельных потоков - 2 по числу ядер процессора). Интенсивность формирования / отправки запросов каждого вида (<em>Rate</em>) для базового шардирования задана равной 10000 запросов/с, в кластере с репликами - 5000 запросов/с исходя из предварительных выводов о нагрузке, при которой фактическая производительность симулятора запросов характеризуется устойчивым достижением уровня, эквивалентного или максимально близкого выбранному значению <em>Rate</em>.

**Команды <em>wrk2</em>**<br/>

<p></p>

<ins><em>wrk2</em> / PUT / basic sharding</ins>
```
wrk -t2 -c64 -d7m -s src/profiling/wrk_scripts/put.lua -R10000 --latency http://127.0.0.1:8080
```

<ins><em>wrk2</em> / GET / basic sharding</ins>
```
wrk -t2 -c64 -d7m -s src/profiling/wrk_scripts/get.lua -R10000 --latency http://127.0.0.1:8080
```

<ins><em>wrk2</em> / PUT / replication</ins>
```
wrk -t2 -c64 -d7m -s src/profiling/wrk_scripts/put.lua -R5000 --latency http://127.0.0.1:8080
```

<ins><em>wrk2</em> / GET / replication</ins>
```
wrk -t2 -c64 -d7m -s src/profiling/wrk_scripts/get.lua -R5000 --latency http://127.0.0.1:8080
```

**Команды <em>async-profiler</em>**<br/>

<p></p>

<ins><em>async-profiler</em> / cpu</ins>
```
./profiler.sh -d 60 -e cpu -f /path/to/output/folder/flame_output_cpu.svg <server_process_pid>
```

<ins><em>async-profiler</em> / alloc</ins>
```
./profiler.sh -d 60 -e alloc -f /path/to/output/folder/flame_output_alloc.svg <server_process_pid>
```

<ins><em>async-profiler</em> / lock</ins>
```
./profiler.sh -d 60 -e lock -f /path/to/output/folder/flame_output_lock.svg <server_pid>
```

Результаты измерений и сравнение этапных конфигураций кластера приведены далее.

### 1. Добавление/изменение записей (PUT)

<ins><em>wrk2</em> outputs / basic sharding</ins>  
```
max@max-Inspiron-15-3573:~/hackdht$ wrk -t2 -c64 -d7m -s src/profiling/wrk_scripts/put.lua -R10000 --latency http://127.0.0.1:8080
Running 7m test @ http://127.0.0.1:8080
  2 threads and 64 connections
  Thread calibration: mean lat.: 799.709ms, rate sampling interval: 2326ms
  Thread calibration: mean lat.: 804.702ms, rate sampling interval: 2433ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     5.43ms   14.70ms 272.13ms   96.90%
    Req/Sec     5.00k    51.11     5.46k    92.44%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    2.76ms
 75.000%    3.81ms
 90.000%    6.69ms
 99.000%   87.42ms
 99.900%  183.42ms
 99.990%  224.00ms
 99.999%  258.30ms
100.000%  272.38ms

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

       0.100     0.000000            1         1.00
       1.238     0.100000       410712         1.11
       1.743     0.200000       820161         1.25
       2.125     0.300000      1230426         1.43
       2.447     0.400000      1641444         1.67
       2.759     0.500000      2050806         2.00
       2.925     0.550000      2255987         2.22
       3.105     0.600000      2462100         2.50
       3.301     0.650000      2665682         2.86
       3.529     0.700000      2870918         3.33
       3.805     0.750000      3076515         4.00
       3.973     0.775000      3178580         4.44
       4.175     0.800000      3281629         5.00
       4.423     0.825000      3382938         5.71
       4.763     0.850000      3485497         6.67
       5.323     0.875000      3588041         8.00
       5.835     0.887500      3639385         8.89
       6.691     0.900000      3690440        10.00
       7.823     0.912500      3741665        11.43
       9.071     0.925000      3792933        13.33
      10.599     0.937500      3844275        16.00
      11.535     0.943750      3869725        17.78
      12.647     0.950000      3895464        20.00
      13.967     0.956250      3920998        22.86
      15.839     0.962500      3946681        26.67
      19.855     0.968750      3972237        32.00
      24.623     0.971875      3985047        35.56
      31.103     0.975000      3997867        40.00
      39.199     0.978125      4010713        45.71
      48.735     0.981250      4023490        53.33
      60.703     0.984375      4036333        64.00
      67.583     0.985938      4042736        71.11
      75.135     0.987500      4049136        80.00
      82.751     0.989062      4055527        91.43
      90.495     0.990625      4061943       106.67
      98.431     0.992188      4068343       128.00
     102.271     0.992969      4071585       142.22
     106.047     0.993750      4074747       160.00
     111.295     0.994531      4077948       182.86
     118.527     0.995313      4081168       213.33
     126.911     0.996094      4084370       256.00
     131.583     0.996484      4085954       284.44
     137.343     0.996875      4087571       320.00
     143.871     0.997266      4089174       365.71
     151.807     0.997656      4090772       426.67
     160.255     0.998047      4092381       512.00
     164.223     0.998242      4093173       568.89
     168.319     0.998437      4093966       640.00
     173.183     0.998633      4094781       731.43
     178.431     0.998828      4095572       853.33
     184.063     0.999023      4096371      1024.00
     187.007     0.999121      4096765      1137.78
     189.823     0.999219      4097177      1280.00
     193.279     0.999316      4097567      1462.86
     196.863     0.999414      4097971      1706.67
     200.319     0.999512      4098365      2048.00
     202.111     0.999561      4098579      2275.56
     204.031     0.999609      4098771      2560.00
     206.079     0.999658      4098974      2925.71
     208.383     0.999707      4099170      3413.33
     211.071     0.999756      4099366      4096.00
     212.863     0.999780      4099469      4551.11
     214.655     0.999805      4099567      5120.00
     216.575     0.999829      4099668      5851.43
     218.623     0.999854      4099767      6826.67
     221.567     0.999878      4099869      8192.00
     222.847     0.999890      4099919      9102.22
     224.511     0.999902      4099969     10240.00
     226.175     0.999915      4100018     11702.86
     228.351     0.999927      4100070     13653.33
     231.039     0.999939      4100122     16384.00
     232.447     0.999945      4100143     18204.44
     234.111     0.999951      4100168     20480.00
     236.287     0.999957      4100193     23405.71
     238.591     0.999963      4100217     27306.67
     241.663     0.999969      4100242     32768.00
     243.327     0.999973      4100255     36408.89
     244.607     0.999976      4100267     40960.00
     246.271     0.999979      4100280     46811.43
     248.831     0.999982      4100292     54613.33
     251.519     0.999985      4100305     65536.00
     252.543     0.999986      4100311     72817.78
     254.719     0.999988      4100317     81920.00
     257.023     0.999989      4100324     93622.86
     259.583     0.999991      4100330    109226.67
     260.863     0.999992      4100337    131072.00
     261.375     0.999993      4100339    145635.56
     262.399     0.999994      4100342    163840.00
     263.935     0.999995      4100346    187245.71
     264.959     0.999995      4100350    218453.33
     265.727     0.999996      4100353    262144.00
     265.727     0.999997      4100353    291271.11
     266.751     0.999997      4100355    327680.00
     267.775     0.999997      4100357    374491.43
     268.031     0.999998      4100358    436906.67
     268.287     0.999998      4100360    524288.00
     268.287     0.999998      4100360    582542.22
     268.543     0.999998      4100361    655360.00
     269.567     0.999999      4100362    748982.86
     270.591     0.999999      4100363    873813.33
     271.359     0.999999      4100364   1048576.00
     271.359     0.999999      4100364   1165084.44
     271.359     0.999999      4100364   1310720.00
     271.615     0.999999      4100365   1497965.71
     271.615     0.999999      4100365   1747626.67
     271.871     1.000000      4100366   2097152.00
     271.871     1.000000      4100366   2330168.89
     271.871     1.000000      4100366   2621440.00
     271.871     1.000000      4100366   2995931.43
     271.871     1.000000      4100366   3495253.33
     272.383     1.000000      4100367   4194304.00
     272.383     1.000000      4100367          inf
#[Mean    =        5.431, StdDeviation   =       14.704]
#[Max     =      272.128, Total count    =      4100367]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  4189947 requests in 7.00m, 331.65MB read
Requests/sec:   9976.03
Transfer/sec:    808.60KB
```
<ins><em>wrk2</em> outputs / replication</ins>  
```
max@max-Inspiron-15-3573:~/hackdht$ wrk -t2 -c64 -d7m -s src/profiling/wrk_scripts/put.lua -R5000 --latency http://127.0.0.1:8080
Running 7m test @ http://127.0.0.1:8080
  2 threads and 64 connections
  Thread calibration: mean lat.: 17.256ms, rate sampling interval: 104ms
  Thread calibration: mean lat.: 16.720ms, rate sampling interval: 99ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     8.01ms   30.33ms 817.15ms   95.77%
    Req/Sec     2.51k   253.42     3.73k    86.87%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.80ms
 75.000%    2.64ms
 90.000%   10.07ms
 99.000%  156.29ms
 99.900%  384.77ms
 99.990%  657.41ms
 99.999%  801.28ms
100.000%  817.66ms

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

       0.242     0.000000            1         1.00
       0.861     0.100000       205117         1.11
       1.126     0.200000       410484         1.25
       1.352     0.300000       615422         1.43
       1.571     0.400000       820452         1.67
       1.802     0.500000      1025354         2.00
       1.927     0.550000      1127300         2.22
       2.065     0.600000      1230104         2.50
       2.221     0.650000      1332957         2.86
       2.405     0.700000      1435382         3.33
       2.645     0.750000      1537042         4.00
       2.807     0.775000      1588334         4.44
       3.027     0.800000      1639633         5.00
       3.361     0.825000      1690616         5.71
       4.073     0.850000      1741871         6.67
       6.147     0.875000      1793057         8.00
       7.803     0.887500      1818684         8.89
      10.071     0.900000      1844332        10.00
      12.839     0.912500      1869918        11.43
      16.351     0.925000      1895531        13.33
      21.071     0.937500      1921172        16.00
      24.159     0.943750      1933974        17.78
      28.335     0.950000      1946758        20.00
      35.999     0.956250      1959556        22.86
      48.447     0.962500      1972368        26.67
      63.551     0.968750      1985173        32.00
      71.551     0.971875      1991572        35.56
      79.423     0.975000      1997998        40.00
      88.575     0.978125      2004373        45.71
     100.159     0.981250      2010775        53.33
     113.151     0.984375      2017177        64.00
     124.095     0.985938      2020394        71.11
     136.319     0.987500      2023583        80.00
     148.991     0.989062      2026789        91.43
     161.791     0.990625      2029998       106.67
     176.127     0.992188      2033192       128.00
     184.063     0.992969      2034800       142.22
     194.303     0.993750      2036396       160.00
     205.695     0.994531      2037989       182.86
     216.191     0.995313      2039592       213.33
     237.311     0.996094      2041191       256.00
     251.391     0.996484      2041995       284.44
     265.215     0.996875      2042799       320.00
     279.551     0.997266      2043611       365.71
     294.655     0.997656      2044395       426.67
     311.039     0.998047      2045198       512.00
     321.279     0.998242      2045597       568.89
     335.871     0.998437      2045995       640.00
     351.231     0.998633      2046403       731.43
     368.127     0.998828      2046796       853.33
     386.815     0.999023      2047202      1024.00
     393.727     0.999121      2047403      1137.78
     402.943     0.999219      2047596      1280.00
     413.183     0.999316      2047804      1462.86
     421.887     0.999414      2047997      1706.67
     427.007     0.999512      2048197      2048.00
     428.543     0.999561      2048297      2275.56
     432.895     0.999609      2048396      2560.00
     436.479     0.999658      2048497      2925.71
     440.063     0.999707      2048595      3413.33
     459.519     0.999756      2048695      4096.00
     473.087     0.999780      2048746      4551.11
     504.575     0.999805      2048795      5120.00
     538.623     0.999829      2048846      5851.43
     579.071     0.999854      2048895      6826.67
     619.519     0.999878      2048945      8192.00
     639.487     0.999890      2048970      9102.22
     662.527     0.999902      2048995     10240.00
     680.447     0.999915      2049020     11702.86
     696.319     0.999927      2049045     13653.33
     720.383     0.999939      2049070     16384.00
     731.135     0.999945      2049083     18204.44
     737.279     0.999951      2049095     20480.00
     748.543     0.999957      2049108     23405.71
     752.639     0.999963      2049120     27306.67
     760.319     0.999969      2049135     32768.00
     761.855     0.999973      2049139     36408.89
     766.463     0.999976      2049145     40960.00
     777.727     0.999979      2049152     46811.43
     788.479     0.999982      2049158     54613.33
     793.599     0.999985      2049165     65536.00
     795.135     0.999986      2049168     72817.78
     796.671     0.999988      2049170     81920.00
     800.767     0.999989      2049174     93622.86
     804.351     0.999991      2049177    109226.67
     806.399     0.999992      2049182    131072.00
     806.399     0.999993      2049182    145635.56
     806.911     0.999994      2049185    163840.00
     806.911     0.999995      2049185    187245.71
     807.423     0.999995      2049189    218453.33
     807.423     0.999996      2049189    262144.00
     807.423     0.999997      2049189    291271.11
     807.423     0.999997      2049189    327680.00
     809.471     0.999997      2049190    374491.43
     810.495     0.999998      2049191    436906.67
     811.519     0.999998      2049192    524288.00
     811.519     0.999998      2049192    582542.22
     811.519     0.999998      2049192    655360.00
     813.055     0.999999      2049193    748982.86
     813.055     0.999999      2049193    873813.33
     813.567     0.999999      2049194   1048576.00
     813.567     0.999999      2049194   1165084.44
     813.567     0.999999      2049194   1310720.00
     813.567     0.999999      2049194   1497965.71
     813.567     0.999999      2049194   1747626.67
     817.663     1.000000      2049195   2097152.00
     817.663     1.000000      2049195          inf
#[Mean    =        8.012, StdDeviation   =       30.334]
#[Max     =      817.152, Total count    =      2049195]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  2099632 requests in 7.00m, 134.16MB read
Requests/sec:   4999.13
Transfer/sec:    327.09KB
```
Динамика быстродействия узлов кластера при переходе к репликации записей имеет явный негативный уклон на всём множестве релевантных метрик. При ощутимом (47%) возрастании средней задержки добавления/изменения данных интенсивность обработки соответствующих запросов сократилась приблизительно наполовину. Признаки значительного ухудшения производительности прослеживаются и в распределении времён отклика: несмотря на определённое (около 30%) снижение среднего интервала ожидания, достигаемое по итогам обслуживания трёх четвертей запросов, кластер, обеспечивающий хранение реплик, критически (до 3 раз в случае с максимальным по временн<em>ы</em>м издержкам ответом) уступает результатам наблюдения базовой конфигурации для запросов, составляющих остальные 25% текущего распределения.<br/>            
<ins>Flamegraph-анализ</ins><br/>  

![put_cpu_basic_shards](resources/flamegraphs/put_cpu_basic_shards.svg)
<p align="center">Рис.1. Выделение ресурса CPU при симулировании PUT-запросов (<em>basic sharding</em>)</p>

![put_cpu_replicas](resources/flamegraphs/put_cpu_replicas.svg)
<p align="center">Рис.2. Выделение ресурса CPU при симулировании PUT-запросов (<em>replication</em>)</p>

В структуре профилей процессорного времени для сравниваемых конфигураций заметен ряд различий, главными среди которых следует назвать нивелирование фактора асинхронной обработки запросов и поддержку процедуры создания и сохранения реплик в ходе истытаний кластера с репликацией. Сравнение данных профилей показывает, что ведущими факторами нагрузки на вычислительный ресурс становятся операции чтения и парсинга данных из буфера, в значительной мере дополняемые генерацией и записью реплик в копии LSM-хранилища на узлах кластера. Этой особенностью текущей реализации сервера, предполагающей объективные эффекты в виде накладных расходов на поддержку репликации (с формированием идентичных записей, обменом данными внутри кластера, определением timestamp-значений для каждой реплики), возможно обосновать значительное ухудшение показателей быстродействия в соответствии с вышеупомянутыми результатами нагрузочных тестов.                                                          

![put_alloc_basic_shards](resources/flamegraphs/put_alloc_basic_shards.svg)
<p align="center">Рис.3. Выделение ресурса RAM при симулировании PUT-запросов (<em>basic sharding</em>)</p>

![put_alloc_replicas](resources/flamegraphs/put_alloc_replicas.svg)
<p align="center">Рис.4. Выделение ресурса RAM при симулировании PUT-запросов (<em>replication</em>)</p>

Релевантные изменения в процессах, протекающих на узлах кластера с созданием реплик, проявляются и в разрезе аллокаций. Профиль сервера в новой конфигурации не содержит признаков вызова асинхронного обработчика, составляющего значимую долю выделений памяти в базовом распределении нагрузки. В то же время часть аллокаций выполняется в рамках операций с репликами (включая преобразования между объектными типами), свидетельством чего, как и в представлении процессорного времени, определены фиксируемые вызовы метода <em>upsertWithMultipleNodes</em>.       

![put_lock_basic_shards](resources/flamegraphs/put_lock_basic_shards.svg)
<p align="center">Рис.5. Профиль lock/monitor при симулировании PUT-запросов (<em>basic sharding</em>)</p>

![put_lock_replicas](resources/flamegraphs/put_lock_replicas.svg)
<p align="center">Рис.6. Профиль lock/monitor при симулировании PUT-запросов (<em>replication</em>)</p>

Для управления совместным доступом в контексте обеспечения репликации характерно достижение взаимоисключений в ходе чтения/парсинга данных, операций с созданием/распространением идентичных записей и передачей запроса на следующий узел в рамках распределённой топологии (проксированием). Таким образом, задача синхронизации доступа к блокирующей очереди, относившаяся к числу основных для потокобезопасного выполнения обработчиков и предполагавшая реализацию особого механизма на предыдущем этапе, утратила свою актуальность, что предопределило своеобразное упрощение состава профиля в новой конфигурации.<br/>               

### 2. Чтение записей (GET)

<ins><em>wrk2</em> outputs / basic sharding</ins>  
```
max@max-Inspiron-15-3573:~/hackdht$ wrk -t2 -c64 -d7m -s src/profiling/wrk_scripts/get.lua -R10000 --latency http://127.0.0.1:8080
Running 7m test @ http://127.0.0.1:8080
  2 threads and 64 connections
  Thread calibration: mean lat.: 52.094ms, rate sampling interval: 429ms
  Thread calibration: mean lat.: 22.398ms, rate sampling interval: 188ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.98ms   14.30ms 591.36ms   98.75%
    Req/Sec     5.01k   176.33     6.95k    94.22%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    2.58ms
 75.000%    3.52ms
 90.000%    4.79ms
 99.000%   23.39ms
 99.900%  191.49ms
 99.990%  526.34ms
 99.999%  579.58ms
100.000%  591.87ms

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

       0.100     0.000000            6         1.00
       1.071     0.100000       409747         1.11
       1.523     0.200000       819463         1.25
       1.906     0.300000      1228255         1.43
       2.253     0.400000      1638765         1.67
       2.583     0.500000      2046910         2.00
       2.751     0.550000      2251295         2.22
       2.925     0.600000      2455768         2.50
       3.109     0.650000      2661280         2.86
       3.305     0.700000      2865294         3.33
       3.523     0.750000      3070260         4.00
       3.645     0.775000      3171977         4.44
       3.783     0.800000      3274739         5.00
       3.943     0.825000      3377098         5.71
       4.139     0.850000      3480591         6.67
       4.395     0.875000      3582114         8.00
       4.563     0.887500      3632332         8.89
       4.791     0.900000      3683956        10.00
       5.119     0.912500      3734977        11.43
       5.687     0.925000      3785845        13.33
       6.791     0.937500      3836968        16.00
       7.499     0.943750      3862465        17.78
       8.247     0.950000      3888079        20.00
       9.031     0.956250      3913812        22.86
       9.895     0.962500      3939287        26.67
      10.959     0.968750      3964763        32.00
      11.623     0.971875      3977647        35.56
      12.367     0.975000      3990404        40.00
      13.247     0.978125      4003206        45.71
      14.303     0.981250      4015974        53.33
      15.735     0.984375      4028724        64.00
      16.751     0.985938      4035123        71.11
      18.239     0.987500      4041504        80.00
      20.943     0.989062      4047915        91.43
      25.343     0.990625      4054286       106.67
      31.119     0.992188      4060676       128.00
      34.559     0.992969      4063881       142.22
      38.847     0.993750      4067080       160.00
      45.023     0.994531      4070267       182.86
      59.103     0.995313      4073459       213.33
      89.023     0.996094      4076659       256.00
     111.039     0.996484      4078257       284.44
     127.999     0.996875      4079854       320.00
     142.847     0.997266      4081460       365.71
     157.183     0.997656      4083050       426.67
     166.143     0.998047      4084651       512.00
     169.727     0.998242      4085456       568.89
     173.183     0.998437      4086254       640.00
     177.407     0.998633      4087048       731.43
     180.863     0.998828      4087854       853.33
     194.047     0.999023      4088650      1024.00
     201.983     0.999121      4089050      1137.78
     208.127     0.999219      4089453      1280.00
     215.935     0.999316      4089849      1462.86
     242.431     0.999414      4090244      1706.67
     300.031     0.999512      4090644      2048.00
     342.271     0.999561      4090844      2275.56
     381.695     0.999609      4091045      2560.00
     415.999     0.999658      4091244      2925.71
     448.511     0.999707      4091445      3413.33
     468.735     0.999756      4091644      4096.00
     478.975     0.999780      4091747      4551.11
     484.095     0.999805      4091843      5120.00
     489.983     0.999829      4091947      5851.43
     495.103     0.999854      4092048      6826.67
     512.511     0.999878      4092143      8192.00
     522.495     0.999890      4092200      9102.22
     526.847     0.999902      4092243     10240.00
     535.551     0.999915      4092298     11702.86
     542.719     0.999927      4092346     13653.33
     551.423     0.999939      4092403     16384.00
     553.983     0.999945      4092420     18204.44
     557.567     0.999951      4092450     20480.00
     559.615     0.999957      4092468     23405.71
     562.687     0.999963      4092493     27306.67
     566.271     0.999969      4092518     32768.00
     567.807     0.999973      4092533     36408.89
     569.343     0.999976      4092543     40960.00
     571.903     0.999979      4092556     46811.43
     574.463     0.999982      4092572     54613.33
     575.487     0.999985      4092581     65536.00
     575.999     0.999986      4092586     72817.78
     578.047     0.999988      4092596     81920.00
     578.559     0.999989      4092599     93622.86
     580.095     0.999991      4092609    109226.67
     580.607     0.999992      4092611    131072.00
     581.631     0.999993      4092614    145635.56
     582.655     0.999994      4092618    163840.00
     584.191     0.999995      4092624    187245.71
     584.191     0.999995      4092624    218453.33
     584.703     0.999996      4092627    262144.00
     585.215     0.999997      4092628    291271.11
     585.727     0.999997      4092630    327680.00
     586.239     0.999997      4092632    374491.43
     586.751     0.999998      4092633    436906.67
     588.799     0.999998      4092635    524288.00
     588.799     0.999998      4092635    582542.22
     589.311     0.999998      4092636    655360.00
     590.335     0.999999      4092637    748982.86
     590.847     0.999999      4092638    873813.33
     591.359     0.999999      4092640   1048576.00
     591.359     0.999999      4092640   1165084.44
     591.359     0.999999      4092640   1310720.00
     591.359     0.999999      4092640   1497965.71
     591.359     0.999999      4092640   1747626.67
     591.871     1.000000      4092642   2097152.00
     591.871     1.000000      4092642          inf
#[Mean    =        3.977, StdDeviation   =       14.305]
#[Max     =      591.360, Total count    =      4092642]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  4188850 requests in 7.00m, 337.44MB read
  Non-2xx or 3xx responses: 1693
Requests/sec:   9973.48
Transfer/sec:    822.71KB
```
<ins><em>wrk2</em> outputs / replication</ins>  
```

```
Результаты серий с получением данных из хранилища фиксируют существенное ухудшение производительности при переходе к распределённой топологии. При том, что средняя задержки возросла на 1,5 мс (~60%), обработка 0,1% запросов в верхнем сегменте интервалов ожидания заняла время, кратно (до 6 раз в случае наиболее продолжительного ответа) превышающее оценки, установленные для реализации нераспределённого сервера. Как и при тестировании в режиме добавления записей, в процессе обслуживания запросов на чтение интенсивность их выполнения составила около 5000 запросов/с, что заметно уступает результату предыдущего этапа.<br/>                  
<ins>Flamegraph-анализ</ins><br/>  

![get_cpu_basic_shards](resources/flamegraphs/get_cpu_basic_shards.svg)
<p align="center">Рис.7. Выделение ресурса CPU при симулировании GET-запросов (<em>basic sharding</em>)</p>

![get_cpu_replication](resources/flamegraphs/get_cpu_replicas.svg)
<p align="center">Рис.8. Выделение ресурса CPU при симулировании GET-запросов (<em>replication</em>)</p>

Аналогично профилю, полученному в ходе операций с PUT-запросами, в текущей структуре пользователей процессорного времени на узле кластера прослеживается действие метода проксирования <em>invoke</em>. Принимая во внимание значительное снижение производительности чтения в распределённой топологии, эффект проксирования запросов, связанный с дополнительной нагрузкой на аппаратные ресурсы, прежде всего ЦПУ, следует рассматривать как релевантный фактор негативной динамики в условиях роста числа перенаправляемых запросов.            

![get_alloc_basic_shards](resources/flamegraphs/get_alloc_basic_shards.svg)
<p align="center">Рис.9. Выделение ресурса RAM при симулировании GET-запросов (<em>basic sharding</em>)</p>

![get_alloc_replicas](resources/flamegraphs/get_alloc_replicas.svg)
<p align="center">Рис.10. Выделение ресурса RAM при симулировании GET-запросов (<em>replication</em>)</p>

Актуальное сравнение триггеров аллокаций идентично их определению в профилях к PUT-запросам. Используя текущие представления, можно утверждать, что различия в топологиях сервера не оказывают влияния на структуру операций, требующих выделения памяти (как минимум на уровне одного узла кластера, подвергнутого профилированию).                   

![get_lock_basic_shards](resources/flamegraphs/get_lock_basic_shards.svg)
<p align="center">Рис.11. Профиль lock/monitor при симулировании GET-запросов (<em>basic sharding</em>)</p>

![get_lock_replicas](resources/flamegraphs/get_lock_replicas.svg)
<p align="center">Рис.12. Профиль lock/monitor при симулировании GET-запросов (<em>replication</em>)</p>

Контроль асинхронного параллелизма при выполнении GET-запросов реализуется с использованием того же механизма взаимоисключений, который гарантирует безопасность критической секции в очереди с PUT-запросами (комбинация экземпляров <em>ReentrantLock</em> и <em>AbstractQueueSynchronizer</em>).
